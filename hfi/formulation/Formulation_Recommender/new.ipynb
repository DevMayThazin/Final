{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arsha,agnimandya,udararoga,vibandha', 'sarvajvara,jirnajvara', 'kandu,tvakvikara,vibandha', 'balaroga,balakshaya,agnimandya,aruchi', 'hridroga,hriddrava,hrid-daurbalya,moha,murchha']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('Formulation-Indications.csv')\n",
    "formulations_lst = list(df1['Name of Medicine'])\n",
    "\n",
    "processed_list = []\n",
    "original_list = list(df1['Main Indications'])\n",
    "for item in original_list:\n",
    "    # Remove spaces and newline characters, convert to lowercase\n",
    "    processed_item = ''.join(item.split()).lower()\n",
    "    processed_list.append(processed_item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symptom description dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms = pd.read_csv('ayurvedic_symptoms_desc.csv')\n",
    "symptoms['Symptom'] = symptoms['Symptom'].str.lower()\n",
    "\n",
    "def symptoms_desc(symptom_name):\n",
    "    row = symptoms[symptoms['Symptom'] == symptom_name.lower()]\n",
    "#     print(row)\n",
    "    if not row.empty:\n",
    "        description = row.iloc[0]['Description']\n",
    "        print(f'Description of \"{symptom_name}\": {description}')\n",
    "    else:\n",
    "        print(f'Symptom \"{symptom_name}\" not found in the DataFrame.')\n",
    "\n",
    "def symptoms_lst_desc(user_symptoms):\n",
    "    for item in user_symptoms:\n",
    "#         print(item)\n",
    "        symptoms_desc(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lists of symptoms\n",
    "list_of_symptoms = processed_list\n",
    "\n",
    "# Flatten the list of lists and split the symptoms using commas and spaces\n",
    "flat_symptoms = [symptom.replace(',', ' ').split() for symptoms in list_of_symptoms for symptom in symptoms.split(',')]\n",
    "\n",
    "# Get unique symptoms as a list\n",
    "unique_symptoms = list(set(symptom for sublist in flat_symptoms for symptom in sublist))\n",
    "\n",
    "import difflib\n",
    "\n",
    "# Your list of correct words (assuming you have a list called unique_symptoms)\n",
    "correct_words = unique_symptoms\n",
    "\n",
    "def correct_symptoms(symptoms):\n",
    "    corrected_symptoms = []\n",
    "    for symptom in symptoms:\n",
    "        corrected_symptom = difflib.get_close_matches(symptom, correct_words, n=1, cutoff=0.6)\n",
    "        if corrected_symptom:\n",
    "            corrected_symptoms.append(corrected_symptom[0])\n",
    "        else:\n",
    "            corrected_symptoms.append(symptom)\n",
    "    return corrected_symptoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean: jvara, kasa\n",
      "Description of \"jvara\": Fever.\n",
      "Description of \"kasa\": Cough.\n",
      "Predicted Formulation: Punarnavadi Kashayam\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "data = {\n",
    "    \"Formulation\": formulations_lst,\n",
    "    \"Symptoms\": processed_list,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the symptom text data into numerical features\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['Symptoms'])\n",
    "\n",
    "# Create and train a classifier (e.g., Naive Bayes)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_tfidf, df['Formulation'])\n",
    "\n",
    "# Spelling Correction\n",
    "user_input = input(\"Enter a list of symptoms separated by spaces: \")\n",
    "input_symptoms = user_input.split()\n",
    "new_symptoms = correct_symptoms(input_symptoms)\n",
    "print(f\"Did you mean: {', '.join(new_symptoms)}\")\n",
    "\n",
    "# Find Symptom Description\n",
    "symptoms_lst_desc(new_symptoms)\n",
    "\n",
    "# Predict Formulation \n",
    "new_symptoms_tfidf = tfidf_vectorizer.transform(new_symptoms)\n",
    "predicted_label = clf.predict(new_symptoms_tfidf)\n",
    "print(f\"Predicted Formulation: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Save in pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
